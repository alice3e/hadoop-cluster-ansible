---
# tasks file for hadoop-master
- name: Update linux apt
  ansible.builtin.apt:
    name: "*"
    state: latest
    update_cache: yes

# https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions -> Java 11 ONLY
- name: Install required packages
  apt:
    name: 
      - openjdk-11-jdk
    state: present

- name: Download Hadoop
  get_url:
    url: "https://downloads.apache.org/hadoop/common/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"
    dest: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    mode: '0755'
    
- name: Create hadoop installer directory
  file:
    path: "{{ hadoop_install_dir }}"
    state: directory
    
- name: Extract Hadoop
  unarchive:
    src: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    dest: "{{ hadoop_install_dir }}"
    remote_src: yes

- name: Create symbolic link for Hadoop
  file:
    src: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}"
    dest: "/usr/local/hadoop"
    state: link

- name: Set environment variables for Hadoop
  blockinfile:
    path: "/etc/profile.d/hadoop.sh"
    block: |
      export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
      export HADOOP_HOME=/usr/local/hadoop
      export PATH=$PATH:$HADOOP_HOME/bin
      export PATH=$PATH:$HADOOP_HOME/sbin
      export HADOOP_MAPRED_HOME=$HADOOP_HOME
      export HADOOP_COMMON_HOME=$HADOOP_HOME
      export HADOOP_HDFS_HOME=$HADOOP_HOME
      export YARN_HOME=$HADOOP_HOME
    create: yes
    mode: "0755"  # Исправлен режим с 7055 на 0755

- name: Source Hadoop environment
  shell: "source /etc/profile.d/hadoop.sh"
  args:
    executable: /bin/bash
    
- name: Set environment variables in /etc/environment
  lineinfile:
    path: /etc/environment
    line: "{{ item }}"
    state: present
  loop:
    - 'JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64'
    - 'HDFS_SECONDARYNAMENODE_USER={{ ansible_user }}'
    - 'HDFS_NAMENODE_USER={{ ansible_user }}'
    - 'HDFS_DATANODE_USER={{ ansible_user }}'
    - 'YARN_NODEMANAGER_USER={{ ansible_user }}'
    - 'YARN_RESOURCEMANAGER_USER={{ ansible_user }}'
  notify:
    - restart hadoop namenode
    - restart hadoop resourcemanager

- name: Download local variables from /etc/environment
  shell: source /etc/environment
  args:
    executable: /bin/bash

- name: Copy Hadoop configuration files
  template:
    src: "{{ item.src }}"
    dest: "/usr/local/hadoop/etc/hadoop/{{ item.dest }}"
  loop:
    - { src: "core-site.xml.j2", dest: "core-site.xml" }
    - { src: "hdfs-site.xml.j2", dest: "hdfs-site.xml" }
    - { src: "mapred-site.xml.j2", dest: "mapred-site.xml" }
    - { src: "yarn-site.xml.j2", dest: "yarn-site.xml" }
  notify:
    - restart hadoop namenode
    - restart hadoop resourcemanager
    - restart hadoop historyserver
    
- name: Format the Hadoop namenode
  command: "/usr/local/hadoop/bin/hdfs namenode -format"
  when: "'master' in group_names"
  notify:
    - restart hadoop namenode

- name: Start HDFS daemons
  shell: /usr/local/hadoop/sbin/start-dfs.sh
  become: true

- name: Start YARN daemons
  shell: /usr/local/hadoop/sbin/start-yarn.sh
  become: true
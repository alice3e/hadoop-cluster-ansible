---
# tasks file for hadoop-master

# --- БЛОК SSH ---
- name: Copy SSH private key
  copy:
    src: "roles/common/files/ssh/hadoop-key"
    dest: "/home/{{ ansible_user }}/.ssh/id_rsa"
    mode: '0600'
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"

- name: Copy SSH public key
  copy:
    src: "roles/common/files/ssh/hadoop-key.pub"
    dest: "/home/{{ ansible_user }}/.ssh/id_rsa.pub"
    mode: '0644'
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"

- name: Configure SSH for seamless cluster communication
  blockinfile:
    path: "/home/{{ ansible_user }}/.ssh/config"
    create: yes
    mode: '0600'
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    block: |
      Host localhost master worker*
        StrictHostKeyChecking no
        UserKnownHostsFile=/dev/null
# --- КОНЕЦ БЛОКА SSH ---

- name: Download Hadoop
  get_url:
    url: "https://downloads.apache.org/hadoop/common/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"
    dest: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    mode: '0755'


- name: Create hadoop installation directory
  file:
    path: "{{ hadoop_install_dir }}" 
    state: directory
    mode: '0755'

- name: Extract Hadoop archive
  unarchive:
    src: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    dest: "{{ hadoop_install_dir }}"
    remote_src: yes


- name: Create symbolic link for Hadoop in /usr/local
  file:
    src: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}"
    dest: "/usr/local/hadoop"
    state: link
  become: yes

- name: Configure JAVA_HOME in hadoop-env.sh
  lineinfile:
    path: "/usr/local/hadoop/etc/hadoop/hadoop-env.sh"
    regexp: '^export JAVA_HOME='
    line: 'export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64'
    state: present
  become: yes

- name: Set system-wide environment variables for Hadoop
  blockinfile:
    path: "/etc/profile.d/hadoop.sh"
    block: |
      export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
      export HADOOP_HOME=/usr/local/hadoop
      export PATH=$PATH:$HADOOP_HOME/bin
      export PATH=$PATH:$HADOOP_HOME/sbin
      export HADOOP_MAPRED_HOME=$HADOOP_HOME
      export HADOOP_COMMON_HOME=$HADOOP_HOME
      export HADOOP_HDFS_HOME=$HADOOP_HOME
      export YARN_HOME=$HADOOP_HOME
      export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
    create: yes
    mode: "0755"
  become: yes

- name: Set environment variables for non-interactive sessions
  lineinfile:
    path: /etc/environment
    regexp: "^{{ item.key }}="
    line: "{{ item.key }}={{ item.value }}"
    state: present
  loop:
    - { key: 'JAVA_HOME', value: '/usr/lib/jvm/java-11-openjdk-amd64' }
    - { key: 'HDFS_NAMENODE_USER', value: '{{ ansible_user }}' }
    - { key: 'HDFS_SECONDARYNAMENODE_USER', value: '{{ ansible_user }}' }
    - { key: 'HDFS_DATANODE_USER', value: '{{ ansible_user }}' }
    - { key: 'YARN_NODEMANAGER_USER', value: '{{ ansible_user }}' }
    - { key: 'YARN_RESOURCEMANAGER_USER', value: '{{ ansible_user }}' }
  become: yes

- name: Stop all Hadoop services on master
  shell: |
    /usr/local/hadoop/bin/mapred --daemon stop historyserver 2>/dev/null || true
    /usr/local/hadoop/bin/yarn --daemon stop resourcemanager 2>/dev/null || true
    /usr/local/hadoop/bin/hdfs --daemon stop namenode 2>/dev/null || true
  args:
    executable: /bin/bash
  become: yes
  become_user: "{{ ansible_user }}"
  ignore_errors: yes

- name: Copy Hadoop configuration files
  template:
    src: "{{ item.src }}"
    dest: "/usr/local/hadoop/etc/hadoop/{{ item.dest }}"
  loop:
    - { src: "core-site.xml.j2", dest: "core-site.xml" }
    - { src: "hdfs-site.xml.j2", dest: "hdfs-site.xml" }
    - { src: "mapred-site.xml.j2", dest: "mapred-site.xml" }
    - { src: "yarn-site.xml.j2", dest: "yarn-site.xml" }
  become: yes

- name: Render Hadoop workers file from inventory
  copy:
    dest: /usr/local/hadoop/etc/hadoop/workers
    content: |
      {% for host in groups['hadoop_worker'] %}
      {{ hostvars[host]['internal_ip'] }}
      {% endfor %}
    mode: '0644'
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
  become: yes

- name: Set correct ownership for all Hadoop files
  file:
    path: "/usr/local/hadoop"
    state: directory
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    recurse: yes
  become: yes

- name: Check if NameNode is already formatted
  stat:
    path: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}/hdfs/namenode/current"
  register: namenode_dir_stat

- name: Format the Hadoop namenode (only once)
  shell: |
    source /etc/profile.d/hadoop.sh
    /usr/local/hadoop/bin/hdfs namenode -format -force
  args:
    executable: /bin/bash
  when: not namenode_dir_stat.stat.exists
  become: yes
  become_user: "{{ ansible_user }}"

- name: Start HDFS NameNode
  shell: |
    source /etc/profile.d/hadoop.sh
    /usr/local/hadoop/bin/hdfs --daemon start namenode
  args:
    executable: /bin/bash
  become: yes
  become_user: "{{ ansible_user }}"

- name: Wait for NameNode to start
  wait_for:
    host: "{{ hostvars[groups['hadoop_master'][0]]['internal_ip'] }}"
    port: 9000
    delay: 5
    timeout: 60

- name: Start YARN ResourceManager
  shell: |
    source /etc/profile.d/hadoop.sh
    /usr/local/hadoop/bin/yarn --daemon start resourcemanager
  args:
    executable: /bin/bash
  become: yes
  become_user: "{{ ansible_user }}"

- name: Start MapReduce HistoryServer
  shell: |
    source /etc/profile.d/hadoop.sh
    /usr/local/hadoop/bin/mapred --daemon start historyserver
  args:
    executable: /bin/bash
  become: yes
  become_user: "{{ ansible_user }}"